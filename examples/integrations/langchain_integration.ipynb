{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TanzoLang + LangChain Integration Example\n",
    "\n",
    "This notebook demonstrates how to load a TanzoLang profile and convert it into a LangChain prompt template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's install the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "!pip install langchain langchain-openai pyyaml\n",
    "\n",
    "# For demonstration, we'll set up a mock API key\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'your-api-key'  # Replace with your actual API key when using"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a TanzoLang Profile\n",
    "\n",
    "Let's load a TanzoLang profile from a YAML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to a TanzoLang profile\n",
    "profile_path = '../../examples/Kai_profile.yaml'  # Adjust the path to your profile\n",
    "\n",
    "# Load the profile\n",
    "def load_profile(path):\n",
    "    path = Path(path)\n",
    "    with open(path, 'r') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "# Load the profile\n",
    "try:\n",
    "    profile = load_profile(profile_path)\n",
    "    print(f\"Successfully loaded profile: {profile.get('profile', {}).get('name', 'Unnamed')}\")\
",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {profile_path}\")\n",
    "    # Create a simple example profile\n",
    "    profile = {\n",
    "        'version': '0.1.0',\n",
    "        'profile': {\n",
    "            'name': 'Example AI Guide',\n",
    "            'description': 'A helpful AI assistant with a balanced personality',\n",
    "            'archetypes': [\n",
    "                {\n",
    "                    'type': 'digital',\n",
    "                    'name': 'The Guide',\n",
    "                    'description': 'A helpful and knowledgeable mentor',\n",
    "                    'attributes': [\n",
    "                        {\n",
    "                            'name': 'wisdom',\n",
    "                            'value': 0.8,\n",
    "                            'description': 'Depth of understanding and insight'\n",
    "                        },\n",
    "                        {\n",
    "                            'name': 'patience',\n",
    "                            'value': 0.9,\n",
    "                            'description': 'Ability to remain calm and helpful'\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    'type': 'digital',\n",
    "                    'name': 'The Explorer',\n",
    "                    'description': 'Curious and adventurous',\n",
    "                    'attributes': [\n",
    "                        {\n",
    "                            'name': 'curiosity',\n",
    "                            'value': 0.85,\n",
    "                            'description': 'Desire to learn and discover'\n",
    "                        },\n",
    "                        {\n",
    "                            'name': 'adaptability',\n",
    "                            'value': 0.75,\n",
    "                            'description': 'Flexibility in new situations'\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            'ikigai': {\n",
    "                'passion': 'Helping others learn and grow',\n",
    "                'mission': 'Making knowledge accessible to all',\n",
    "                'profession': 'Digital guide and assistant',\n",
    "                'vocation': 'Creating clarity from complexity'\n",
    "            },\n",
    "            'symbolism': {\n",
    "                'primary_element': 'air',\n",
    "                'color': 'blue',\n",
    "                'animal': 'owl',\n",
    "                'recurring_motifs': ['paths', 'bridges', 'light']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    print(\"Created example profile instead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a LangChain Prompt Template\n",
    "\n",
    "Now, let's convert the TanzoLang profile into a LangChain prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def extract_archetype_info(profile):\n",
    "    prof = profile.get('profile', {})\n",
    "    name = prof.get('name', 'AI Assistant')\n",
    "    description = prof.get('description', 'An AI assistant')\n",
    "    \n",
    "    # Gather archetype information\n",
    "    archetype_strings = []\n",
    "    for arch in prof.get('archetypes', []):\n",
    "        arch_type = arch.get('type', 'unknown')\n",
    "        arch_name = arch.get('name', 'Unnamed')\n",
    "        arch_desc = arch.get('description', '')\n",
    "        archetype_strings.append(f\"- {arch_name} ({arch_type}): {arch_desc}\")\n",
    "    \n",
    "    # Gather attribute information\n",
    "    attribute_strings = []\n",
    "    for arch in prof.get('archetypes', []):\n",
    "        for attr in arch.get('attributes', []):\n",
    "            attr_name = attr.get('name', 'unnamed')\n",
    "            attr_desc = attr.get('description', '')\n",
    "            attr_value = attr.get('value')\n",
    "            \n",
    "            # Format the value based on its type\n",
    "            if isinstance(attr_value, dict) and 'distribution' in attr_value:\n",
    "                dist_type = attr_value.get('distribution')\n",
    "                if dist_type == 'normal':\n",
    "                    mean = attr_value.get('mean', 0)\n",
    "                    value_str = f\"around {mean}\"\n",
    "                elif dist_type == 'uniform':\n",
    "                    min_val = attr_value.get('min', 0)\n",
    "                    max_val = attr_value.get('max', 0)\n",
    "                    value_str = f\"between {min_val} and {max_val}\"\n",
    "                elif dist_type == 'discrete':\n",
    "                    values = attr_value.get('values', [])\n",
    "                    value_str = f\"one of {', '.join(str(v) for v in values)}\"\n",
    "                else:\n",
    "                    value_str = \"variable\"\n",
    "            elif isinstance(attr_value, (int, float)):\n",
    "                # Scale 0-1 values to a more descriptive range\n",
    "                if 0 <= attr_value <= 1:\n",
    "                    if attr_value >= 0.9:\n",
    "                        value_str = \"very high\"\n",
    "                    elif attr_value >= 0.7:\n",
    "                        value_str = \"high\"\n",
    "                    elif attr_value >= 0.4:\n",
    "                        value_str = \"moderate\"\n",
    "                    elif attr_value >= 0.2:\n",
    "                        value_str = \"low\"\n",
    "                    else:\n",
    "                        value_str = \"very low\"\n",
    "                else:\n",
    "                    value_str = str(attr_value)\n",
    "            else:\n",
    "                value_str = str(attr_value) if attr_value is not None else \"unspecified\"\n",
    "                \n",
    "            attribute_strings.append(f\"- {attr_name} ({value_str}): {attr_desc}\")\n",
    "    \n",
    "    # Gather symbolic elements\n",
    "    symbol_strings = []\n",
    "    for field in ['lineage', 'ikigai', 'memory', 'scars', 'symbolism']:\n",
    "        if field in prof:\n",
    "            if field == 'ikigai':\n",
    "                ikigai = prof[field]\n",
    "                if isinstance(ikigai, dict):\n",
    "                    for key, value in ikigai.items():\n",
    "                        symbol_strings.append(f\"- Your {key}: {value}\")\n",
    "            elif field == 'symbolism':\n",
    "                symbolism = prof[field]\n",
    "                if isinstance(symbolism, dict):\n",
    "                    for key, value in symbolism.items():\n",
    "                        if isinstance(value, list):\n",
    "                            symbol_strings.append(f\"- Your {key.replace('_', ' ')}: {', '.join(value)}\")\n",
    "                        else:\n",
    "                            symbol_strings.append(f\"- Your {key.replace('_', ' ')}: {value}\")\n",
    "            elif isinstance(prof[field], list):\n",
    "                for item in prof[field]:\n",
    "                    if isinstance(item, dict) and 'name' in item:\n",
    "                        desc = item.get('description', '')\n",
    "                        symbol_strings.append(f\"- {item['name']}: {desc}\")\n",
    "    \n",
    "    return {\n",
    "        'name': name,\n",
    "        'description': description,\n",
    "        'archetypes': '\\n'.join(archetype_strings),\n",
    "        'attributes': '\\n'.join(attribute_strings),\n",
    "        'symbols': '\\n'.join(['Your symbolic elements include:'] + symbol_strings) if symbol_strings else ''\n",
    "    }\n",
    "\n",
    "# Extract information from the profile\n",
    "profile_info = extract_archetype_info(profile)\n",
    "\n",
    "# Create a prompt template\n",
    "template = \"\"\"I want you to act as {name}, {description}.\n",
    "\n",
    "Your personality is based on the following archetypes:\n",
    "{archetypes}\n",
    "\n",
    "Your key attributes and traits are:\n",
    "{attributes}\n",
    "\n",
    "{symbols}\n",
    "\n",
    "Respond to the following as {name}: {input}\"\"\"\n",
    "\n",
    "# Create the LangChain prompt template\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"input\"],\n",
    "    partial_variables={\n",
    "        \"name\": profile_info['name'],\n",
    "        \"description\": profile_info['description'],\n",
    "        \"archetypes\": profile_info['archetypes'],\n",
    "        \"attributes\": profile_info['attributes'],\n",
    "        \"symbols\": profile_info['symbols']\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\nCreated LangChain Prompt Template:\\n\")\n",
    "print(prompt.template)\n",
    "\n",
    "# Format the prompt with an example input\n",
    "example_input = \"Tell me about yourself.\"\n",
    "formatted_prompt = prompt.format(input=example_input)\n",
    "\n",
    "print(\"\\nExample Formatted Prompt:\\n\")\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Prompt with LangChain\n",
    "\n",
    "Now let's use the prompt with a LangChain model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# This will use the OpenAI API - make sure you have set your API key\n",
    "# For demonstration only - comment out or replace with your preferred model\n",
    "# If you don't have an API key, you can skip this cell\n",
    "\n",
    "try:\n",
    "    # Initialize the language model\n",
    "    llm = ChatOpenAI(temperature=0.7)  # Adjust temperature as needed\n",
    "    \n",
    "    # Create a chain with the prompt and language model\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    \n",
    "    # Execute the chain with an example input\n",
    "    response = chain.invoke({\"input\": \"Tell me about yourself and how you see the world.\"})\n",
    "    \n",
    "    print(\"\\nAI Response:\\n\")\n",
    "    print(response['text'])\n",
    "except Exception as e:\n",
    "    print(f\"\\nCould not run the model: {e}\")\n",
    "    print(\"To use this functionality, please set up your OpenAI API key.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Complete Integration Function\n",
    "\n",
    "Let's wrap everything in a reusable function that can be imported into other projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "def tanzo_to_langchain(profile_path, model=None):\n",
    "    \"\"\"\n",
    "    Convert a TanzoLang profile to a LangChain setup.\n",
    "    \n",
    "    Args:\n",
    "        profile_path: Path to the TanzoLang profile file\n",
    "        model: Optional LangChain model to use\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the prompt template and chain (if model is provided)\n",
    "    \"\"\"\n",
    "    # Load the profile\n",
    "    try:\n",
    "        with open(profile_path, 'r') as f:\n",
    "            if profile_path.endswith(('.yaml', '.yml')):\n",
    "                profile = yaml.safe_load(f)\n",
    "            elif profile_path.endswith('.json'):\n",
    "                import json\n",
    "                profile = json.load(f)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported file format: {profile_path}\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error loading profile: {e}\")\n",
    "    \n",
    "    # Extract profile information\n",
    "    profile_info = extract_archetype_info(profile)\n",
    "    \n",
    "    # Create the prompt template\n",
    "    template = \"\"\"I want you to act as {name}, {description}.\n",
    "\n",
    "Your personality is based on the following archetypes:\n",
    "{archetypes}\n",
    "\n",
    "Your key attributes and traits are:\n",
    "{attributes}\n",
    "\n",
    "{symbols}\n",
    "\n",
    "Respond to the following as {name}: {input}\"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"input\"],\n",
    "        partial_variables={\n",
    "            \"name\": profile_info['name'],\n",
    "            \"description\": profile_info['description'],\n",
    "            \"archetypes\": profile_info['archetypes'],\n",
    "            \"attributes\": profile_info['attributes'],\n",
    "            \"symbols\": profile_info['symbols']\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    result = {\n",
    "        'prompt': prompt,\n",
    "        'profile_info': profile_info\n",
    "    }\n",
    "    \n",
    "    # If a model is provided, create a chain\n",
    "    if model is not None:\n",
    "        chain = LLMChain(llm=model, prompt=prompt)\n",
    "        result['chain'] = chain\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "print(\"\\nTo use this in your own code:\\n\")\n",
    "print(\"```python\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Set up your model\n",
    "model = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "# Convert TanzoLang profile to LangChain\n",
    "result = tanzo_to_langchain('path/to/profile.yaml', model)\n",
    "\n",
    "# Use the chain\n",
    "response = result['chain'].invoke({\"input\": \"Your question here\"})\n",
    "print(response['text'])\n",
    "```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates how to convert a TanzoLang profile into a LangChain prompt template. The approach can be extended to support more complex prompt engineering based on the TanzoLang specification, such as incorporating specific archetypes, handling different attribute distributions, and incorporating symbolic elements in more sophisticated ways.\n",
    "\n",
    "The integration allows AI developers to use TanzoLang's rich personality specification system to craft detailed prompts for specific AI behaviors and characteristics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 }
}
